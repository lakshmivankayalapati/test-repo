name: Comprehensive CI Testing Pipeline

on:
  pull_request:
    branches: [ dev, main ]
  push:
    branches: [ dev, main ]

env:
  FLUTTER_VERSION: "3.32.5"
  JAVA_VERSION: "17"
  ANDROID_API_LEVEL: "33"
  ANDROID_BUILD_TOOLS: "33.0.0"

permissions:
  checks: write
  contents: read
  pull-requests: write

jobs:
  # Unit Tests
  unit-tests:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Run Flutter Tests
        id: run-tests
        run: |
          flutter test test/unit/ --machine > test_output.json
          UNIT_EXIT_CODE=$?
          echo "exit_code=$UNIT_EXIT_CODE" >> $GITHUB_OUTPUT

      - name: Generate Markdown Report from Test Output
        run: |
          python3 <<EOF
          import json
          import sys

          try:
              with open("test_output.json") as f:
                  lines = [json.loads(l) for l in f if l.strip().startswith("{")]

              total = passed = failed = 0
              suite_data = {}
              current_suite = None
              test_results = {}  # Track individual test results

              # First pass: collect all test results
              for entry in lines:
                  if entry['type'] == 'suite':
                      current_suite = entry['suite']['path']
                  elif entry['type'] == 'testStart':
                      test_name = entry['test']['name']
                      test_results[test_name] = {
                          'suite': current_suite,
                          'status': 'unknown'
                      }
                  elif entry['type'] == 'testDone':
                      test_name = entry['test']['name']
                      if test_name in test_results:
                          test_results[test_name]['status'] = entry['result']
                          if entry['result'] == 'success':
                              passed += 1
                          else:
                              failed += 1
                          total += 1

              # Second pass: group by suite
              for test_name, test_info in test_results.items():
                  suite_path = test_info['suite']
                  if suite_path:
                      # Extract suite name from path
                      suite_name = suite_path.split('/')[-1].replace('_test.dart', '').replace('_', ' ').title()
                      if suite_name not in suite_data:
                          suite_data[suite_name] = {"passed": 0, "failed": 0}
                      
                      if test_info['status'] == 'success':
                          suite_data[suite_name]["passed"] += 1
                      else:
                          suite_data[suite_name]["failed"] += 1

              with open("unit_test_report.md", "w") as f:
                  f.write("# 🔧 Unit Tests Report\\n\\n")
                  f.write("## 📊 Summary\\n\\n")
                  f.write("| Metric | Value |\\n|--------|-------|\\n")
                  f.write(f"| **Status** | {'✅ PASSED' if failed == 0 else '❌ FAILED'} |\\n")
                  f.write(f"| **Total Tests** | {total} |\\n")
                  f.write(f"| **Passed Tests** | {passed} |\\n")
                  f.write(f"| **Failed Tests** | {failed} |\\n")
                  f.write(f"| **Success Rate** | {round((passed/total)*100) if total else 0}% |\\n\\n")

                  f.write("## 📋 Test Suite Results\\n\\n")
                  for suite, stats in suite_data.items():
                      suite_total = stats["passed"] + stats["failed"]
                      status = "✅ PASSED" if stats["failed"] == 0 else "❌ FAILED"
                      f.write(f"### 🧪 {suite}\\n")
                      f.write(f"- **Status**: {status}\\n")
                      f.write(f"- **Tests**: {stats['passed']}/{suite_total} passed\\n")
                      f.write(f"- **Failed Tests**: {stats['failed']}\\n\\n")

                  if failed == 0:
                      f.write("## ✅ All Unit Tests Passed!\\n")
                  else:
                      f.write("## ❌ Some Unit Tests Failed\\n")
                      f.write("Check the CI logs for detailed failure information.\\n")

                  f.write("\\n---\\n*Report generated automatically by GitHub Actions CI Pipeline*\\n")

          except Exception as e:
              print(f"Error processing test output: {e}")
              # Create a basic report if parsing fails
              with open("unit_test_report.md", "w") as f:
                  f.write("# 🔧 Unit Tests Report\\n\\n")
                  f.write("## ❌ Error Processing Test Results\\n\\n")
                  f.write("Unable to parse test output. Check the CI logs for details.\\n")
          EOF

      - name: Set test results outputs
        id: test-results
        run: |
          # Read the report to extract values with better parsing
          TOTAL_TESTS=$(grep "Total Tests" unit_test_report.md | sed 's/.*Total Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          PASSED_TESTS=$(grep "Passed Tests" unit_test_report.md | sed 's/.*Passed Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          FAILED_TESTS=$(grep "Failed Tests" unit_test_report.md | sed 's/.*Failed Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          
          # Debug output
          echo "Debug: Raw grep results:"
          echo "TOTAL_TESTS_RAW: $(grep 'Total Tests' unit_test_report.md)"
          echo "PASSED_TESTS_RAW: $(grep 'Passed Tests' unit_test_report.md)"
          echo "FAILED_TESTS_RAW: $(grep 'Failed Tests' unit_test_report.md)"
          
          # Fallback parsing if the above doesn't work
          if [ -z "$TOTAL_TESTS" ] || [ "$TOTAL_TESTS" = "" ]; then
            TOTAL_TESTS=$(grep "Total Tests" unit_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          if [ -z "$PASSED_TESTS" ] || [ "$PASSED_TESTS" = "" ]; then
            PASSED_TESTS=$(grep "Passed Tests" unit_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          if [ -z "$FAILED_TESTS" ] || [ "$FAILED_TESTS" = "" ]; then
            FAILED_TESTS=$(grep "Failed Tests" unit_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          
          # Ensure we have valid numbers
          TOTAL_TESTS=${TOTAL_TESTS:-0}
          PASSED_TESTS=${PASSED_TESTS:-0}
          FAILED_TESTS=${FAILED_TESTS:-0}
          
          echo "Debug: Parsed values:"
          echo "TOTAL_TESTS: $TOTAL_TESTS"
          echo "PASSED_TESTS: $PASSED_TESTS"
          echo "FAILED_TESTS: $FAILED_TESTS"
          
          # Determine status
          if [ "$FAILED_TESTS" = "0" ] && [ "$TOTAL_TESTS" -gt 0 ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Get test output for detailed reporting
          TEST_OUTPUT=$(cat test_output.json | head -50)
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "failure_details=Check unit_test_report.md for details" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$TEST_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: |
            test_output.json
            unit_test_report.md
          retention-days: 30

  # Widget Tests
  widget-tests:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Run Flutter Tests
        id: run-tests
        run: |
          flutter test test/widget_test.dart --machine > test_output.json
          WIDGET_EXIT_CODE=$?
          echo "exit_code=$WIDGET_EXIT_CODE" >> $GITHUB_OUTPUT

      - name: Generate Markdown Report from Test Output
        run: |
          python3 <<EOF
          import json
          import sys

          try:
              with open("test_output.json") as f:
                  lines = [json.loads(l) for l in f if l.strip().startswith("{")]

              total = passed = failed = 0
              suite_data = {}
              current_suite = None
              test_results = {}  # Track individual test results

              # First pass: collect all test results
              for entry in lines:
                  if entry['type'] == 'suite':
                      current_suite = entry['suite']['path']
                  elif entry['type'] == 'testStart':
                      test_name = entry['test']['name']
                      test_results[test_name] = {
                          'suite': current_suite,
                          'status': 'unknown'
                      }
                  elif entry['type'] == 'testDone':
                      test_name = entry['test']['name']
                      if test_name in test_results:
                          test_results[test_name]['status'] = entry['result']
                          if entry['result'] == 'success':
                              passed += 1
                          else:
                              failed += 1
                          total += 1

              # Second pass: group by suite
              for test_name, test_info in test_results.items():
                  suite_path = test_info['suite']
                  if suite_path:
                      # Extract suite name from path
                      suite_name = suite_path.split('/')[-1].replace('_test.dart', '').replace('_', ' ').title()
                      if suite_name not in suite_data:
                          suite_data[suite_name] = {"passed": 0, "failed": 0}
                      
                      if test_info['status'] == 'success':
                          suite_data[suite_name]["passed"] += 1
                      else:
                          suite_data[suite_name]["failed"] += 1

              with open("widget_test_report.md", "w") as f:
                  f.write("# 🎨 Widget Tests Report\\n\\n")
                  f.write("## 📊 Summary\\n\\n")
                  f.write("| Metric | Value |\\n|--------|-------|\\n")
                  f.write(f"| **Status** | {'✅ PASSED' if failed == 0 else '❌ FAILED'} |\\n")
                  f.write(f"| **Total Tests** | {total} |\\n")
                  f.write(f"| **Passed Tests** | {passed} |\\n")
                  f.write(f"| **Failed Tests** | {failed} |\\n")
                  f.write(f"| **Success Rate** | {round((passed/total)*100) if total else 0}% |\\n\\n")

                  f.write("## 📋 Test Suite Results\\n\\n")
                  for suite, stats in suite_data.items():
                      suite_total = stats["passed"] + stats["failed"]
                      status = "✅ PASSED" if stats["failed"] == 0 else "❌ FAILED"
                      f.write(f"### 🧪 {suite}\\n")
                      f.write(f"- **Status**: {status}\\n")
                      f.write(f"- **Tests**: {stats['passed']}/{suite_total} passed\\n")
                      f.write(f"- **Failed Tests**: {stats['failed']}\\n\\n")

                  if failed == 0:
                      f.write("## ✅ All Widget Tests Passed!\\n")
                  else:
                      f.write("## ❌ Some Widget Tests Failed\\n")
                      f.write("Check the CI logs for detailed failure information.\\n")

                  f.write("\\n---\\n*Report generated automatically by GitHub Actions CI Pipeline*\\n")

          except Exception as e:
              print(f"Error processing test output: {e}")
              # Create a basic report if parsing fails
              with open("widget_test_report.md", "w") as f:
                  f.write("# 🎨 Widget Tests Report\\n\\n")
                  f.write("## ❌ Error Processing Test Results\\n\\n")
                  f.write("Unable to parse test output. Check the CI logs for details.\\n")
          EOF

      - name: Set test results outputs
        id: test-results
        run: |
          # Read the report to extract values with better parsing
          TOTAL_TESTS=$(grep "Total Tests" widget_test_report.md | sed 's/.*Total Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          PASSED_TESTS=$(grep "Passed Tests" widget_test_report.md | sed 's/.*Passed Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          FAILED_TESTS=$(grep "Failed Tests" widget_test_report.md | sed 's/.*Failed Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          
          # Debug output
          echo "Debug: Raw grep results:"
          echo "TOTAL_TESTS_RAW: $(grep 'Total Tests' widget_test_report.md)"
          echo "PASSED_TESTS_RAW: $(grep 'Passed Tests' widget_test_report.md)"
          echo "FAILED_TESTS_RAW: $(grep 'Failed Tests' widget_test_report.md)"
          
          # Fallback parsing if the above doesn't work
          if [ -z "$TOTAL_TESTS" ] || [ "$TOTAL_TESTS" = "" ]; then
            TOTAL_TESTS=$(grep "Total Tests" widget_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          if [ -z "$PASSED_TESTS" ] || [ "$PASSED_TESTS" = "" ]; then
            PASSED_TESTS=$(grep "Passed Tests" widget_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          if [ -z "$FAILED_TESTS" ] || [ "$FAILED_TESTS" = "" ]; then
            FAILED_TESTS=$(grep "Failed Tests" widget_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          
          # Ensure we have valid numbers
          TOTAL_TESTS=${TOTAL_TESTS:-0}
          PASSED_TESTS=${PASSED_TESTS:-0}
          FAILED_TESTS=${FAILED_TESTS:-0}
          
          echo "Debug: Parsed values:"
          echo "TOTAL_TESTS: $TOTAL_TESTS"
          echo "PASSED_TESTS: $PASSED_TESTS"
          echo "FAILED_TESTS: $FAILED_TESTS"
          
          # Determine status
          if [ "$FAILED_TESTS" = "0" ] && [ "$TOTAL_TESTS" -gt 0 ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Get test output for detailed reporting
          TEST_OUTPUT=$(cat test_output.json | head -50)
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "failure_details=Check widget_test_report.md for details" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$TEST_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: widget-test-results
          path: |
            test_output.json
            widget_test_report.md
          retention-days: 30

  # Accessibility Tests
  accessibility-tests:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Run Flutter Tests
        id: run-tests
        run: |
          flutter test test/accessibility_test.dart --machine > test_output.json
          ACCESSIBILITY_EXIT_CODE=$?
          echo "exit_code=$ACCESSIBILITY_EXIT_CODE" >> $GITHUB_OUTPUT

      - name: Generate Markdown Report from Test Output
        run: |
          python3 <<EOF
          import json
          import sys

          try:
              with open("test_output.json") as f:
                  lines = [json.loads(l) for l in f if l.strip().startswith("{")]

              total = passed = failed = 0
              suite_data = {}
              current_suite = None
              test_results = {}  # Track individual test results

              # First pass: collect all test results
              for entry in lines:
                  if entry['type'] == 'suite':
                      current_suite = entry['suite']['path']
                  elif entry['type'] == 'testStart':
                      test_name = entry['test']['name']
                      test_results[test_name] = {
                          'suite': current_suite,
                          'status': 'unknown'
                      }
                  elif entry['type'] == 'testDone':
                      test_name = entry['test']['name']
                      if test_name in test_results:
                          test_results[test_name]['status'] = entry['result']
                          if entry['result'] == 'success':
                              passed += 1
                          else:
                              failed += 1
                          total += 1

              # Second pass: group by suite
              for test_name, test_info in test_results.items():
                  suite_path = test_info['suite']
                  if suite_path:
                      # Extract suite name from path
                      suite_name = suite_path.split('/')[-1].replace('_test.dart', '').replace('_', ' ').title()
                      if suite_name not in suite_data:
                          suite_data[suite_name] = {"passed": 0, "failed": 0}
                      
                      if test_info['status'] == 'success':
                          suite_data[suite_name]["passed"] += 1
                      else:
                          suite_data[suite_name]["failed"] += 1

              with open("accessibility_test_report.md", "w") as f:
                  f.write("# ♿ Accessibility Tests Report\\n\\n")
                  f.write("## 📊 Summary\\n\\n")
                  f.write("| Metric | Value |\\n|--------|-------|\\n")
                  f.write(f"| **Status** | {'✅ PASSED' if failed == 0 else '❌ FAILED'} |\\n")
                  f.write(f"| **Total Tests** | {total} |\\n")
                  f.write(f"| **Passed Tests** | {passed} |\\n")
                  f.write(f"| **Failed Tests** | {failed} |\\n")
                  f.write(f"| **Success Rate** | {round((passed/total)*100) if total else 0}% |\\n\\n")

                  f.write("## 📋 Test Suite Results\\n\\n")
                  for suite, stats in suite_data.items():
                      suite_total = stats["passed"] + stats["failed"]
                      status = "✅ PASSED" if stats["failed"] == 0 else "❌ FAILED"
                      f.write(f"### 🧪 {suite}\\n")
                      f.write(f"- **Status**: {status}\\n")
                      f.write(f"- **Tests**: {stats['passed']}/{suite_total} passed\\n")
                      f.write(f"- **Failed Tests**: {stats['failed']}\\n\\n")

                  if failed == 0:
                      f.write("## ✅ All Accessibility Tests Passed!\\n")
                  else:
                      f.write("## ❌ Some Accessibility Tests Failed\\n")
                      f.write("Check the CI logs for detailed failure information.\\n")

                  f.write("\\n---\\n*Report generated automatically by GitHub Actions CI Pipeline*\\n")

          except Exception as e:
              print(f"Error processing test output: {e}")
              # Create a basic report if parsing fails
              with open("accessibility_test_report.md", "w") as f:
                  f.write("# ♿ Accessibility Tests Report\\n\\n")
                  f.write("## ❌ Error Processing Test Results\\n\\n")
                  f.write("Unable to parse test output. Check the CI logs for details.\\n")
          EOF

      - name: Set test results outputs
        id: test-results
        run: |
          # Read the report to extract values with better parsing
          TOTAL_TESTS=$(grep "Total Tests" accessibility_test_report.md | sed 's/.*Total Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          PASSED_TESTS=$(grep "Passed Tests" accessibility_test_report.md | sed 's/.*Passed Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          FAILED_TESTS=$(grep "Failed Tests" accessibility_test_report.md | sed 's/.*Failed Tests.*| \([0-9]*\) |.*/\1/' | tr -d ' ')
          
          # Debug output
          echo "Debug: Raw grep results:"
          echo "TOTAL_TESTS_RAW: $(grep 'Total Tests' accessibility_test_report.md)"
          echo "PASSED_TESTS_RAW: $(grep 'Passed Tests' accessibility_test_report.md)"
          echo "FAILED_TESTS_RAW: $(grep 'Failed Tests' accessibility_test_report.md)"
          
          # Fallback parsing if the above doesn't work
          if [ -z "$TOTAL_TESTS" ] || [ "$TOTAL_TESTS" = "" ]; then
            TOTAL_TESTS=$(grep "Total Tests" accessibility_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          if [ -z "$PASSED_TESTS" ] || [ "$PASSED_TESTS" = "" ]; then
            PASSED_TESTS=$(grep "Passed Tests" accessibility_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          if [ -z "$FAILED_TESTS" ] || [ "$FAILED_TESTS" = "" ]; then
            FAILED_TESTS=$(grep "Failed Tests" accessibility_test_report.md | grep -o "[0-9]*" | head -1)
          fi
          
          # Ensure we have valid numbers
          TOTAL_TESTS=${TOTAL_TESTS:-0}
          PASSED_TESTS=${PASSED_TESTS:-0}
          FAILED_TESTS=${FAILED_TESTS:-0}
          
          echo "Debug: Parsed values:"
          echo "TOTAL_TESTS: $TOTAL_TESTS"
          echo "PASSED_TESTS: $PASSED_TESTS"
          echo "FAILED_TESTS: $FAILED_TESTS"
          
          # Determine status
          if [ "$FAILED_TESTS" = "0" ] && [ "$TOTAL_TESTS" -gt 0 ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Get test output for detailed reporting
          TEST_OUTPUT=$(cat test_output.json | head -50)
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "failure_details=Check accessibility_test_report.md for details" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$TEST_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: accessibility-test-results
          path: |
            test_output.json
            accessibility_test_report.md
          retention-days: 30

  # Golden Tests
  golden-tests:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Install dependencies for golden tests
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libwebkit2gtk-4.0-dev \
            libwebkit2gtk-4.0-37 \
            libwebkit2gtk-4.1-0 \
            xvfb \
            || echo "Some packages not found, continuing with available ones"

      - name: Run Flutter Tests
        id: run-tests
        run: |
          flutter test goldens/golden_test.dart --machine > test_output.json
          GOLDEN_EXIT_CODE=$?
          echo "exit_code=$GOLDEN_EXIT_CODE" >> $GITHUB_OUTPUT

      - name: Generate Markdown Report from Test Output
        run: |
          python3 <<EOF
          import json
          import sys

          try:
              with open("test_output.json") as f:
                  lines = [json.loads(l) for l in f if l.strip().startswith("{")]

              total = passed = failed = 0
              suite_data = {}
              current_suite = None
              test_results = {}  # Track individual test results

              # First pass: collect all test results
              for entry in lines:
                  if entry['type'] == 'suite':
                      current_suite = entry['suite']['path']
                  elif entry['type'] == 'testStart':
                      test_name = entry['test']['name']
                      test_results[test_name] = {
                          'suite': current_suite,
                          'status': 'unknown'
                      }
                  elif entry['type'] == 'testDone':
                      test_name = entry['test']['name']
                      if test_name in test_results:
                          test_results[test_name]['status'] = entry['result']
                          if entry['result'] == 'success':
                              passed += 1
                          else:
                              failed += 1
                          total += 1

              # Second pass: group by suite
              for test_name, test_info in test_results.items():
                  suite_path = test_info['suite']
                  if suite_path:
                      # Extract suite name from path
                      suite_name = suite_path.split('/')[-1].replace('_test.dart', '').replace('_', ' ').title()
                      if suite_name not in suite_data:
                          suite_data[suite_name] = {"passed": 0, "failed": 0}
                      
                      if test_info['status'] == 'success':
                          suite_data[suite_name]["passed"] += 1
                      else:
                          suite_data[suite_name]["failed"] += 1

              with open("golden_test_report.md", "w") as f:
                  f.write("# 📸 Golden Tests Report\\n\\n")
                  f.write("## 📊 Summary\\n\\n")
                  f.write("| Metric | Value |\\n|--------|-------|\\n")
                  f.write(f"| **Status** | {'✅ PASSED' if failed == 0 else '❌ FAILED'} |\\n")
                  f.write(f"| **Total Tests** | {total} |\\n")
                  f.write(f"| **Passed Tests** | {passed} |\\n")
                  f.write(f"| **Failed Tests** | {failed} |\\n")
                  f.write(f"| **Success Rate** | {round((passed/total)*100) if total else 0}% |\\n\\n")

                  f.write("## 📋 Test Suite Results\\n\\n")
                  for suite, stats in suite_data.items():
                      suite_total = stats["passed"] + stats["failed"]
                      status = "✅ PASSED" if stats["failed"] == 0 else "❌ FAILED"
                      f.write(f"### 🧪 {suite}\\n")
                      f.write(f"- **Status**: {status}\\n")
                      f.write(f"- **Tests**: {stats['passed']}/{suite_total} passed\\n")
                      f.write(f"- **Failed Tests**: {stats['failed']}\\n\\n")

                  if failed == 0:
                      f.write("## ✅ All Golden Tests Passed!\\n")
                  else:
                      f.write("## ❌ Some Golden Tests Failed\\n")
                      f.write("Check the CI logs for detailed failure information.\\n")

                  f.write("\\n---\\n*Report generated automatically by GitHub Actions CI Pipeline*\\n")

          except Exception as e:
              print(f"Error processing test output: {e}")
              # Create a basic report if parsing fails
              with open("golden_test_report.md", "w") as f:
                  f.write("# 📸 Golden Tests Report\\n\\n")
                  f.write("## ❌ Error Processing Test Results\\n\\n")
                  f.write("Unable to parse test output. Check the CI logs for details.\\n")
          EOF

      - name: Set test results outputs
        id: test-results
        run: |
          # Read the report to extract values
          TOTAL_TESTS=$(grep "Total Tests" golden_test_report.md | grep -o "[0-9]*" | head -1)
          PASSED_TESTS=$(grep "Passed Tests" golden_test_report.md | grep -o "[0-9]*" | head -1)
          FAILED_TESTS=$(grep "Failed Tests" golden_test_report.md | grep -o "[0-9]*" | head -1)
          
          # Determine status
          if [ "$FAILED_TESTS" = "0" ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Get test output for detailed reporting
          TEST_OUTPUT=$(cat test_output.json | head -50)
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=${PASSED_TESTS:-0}" >> $GITHUB_OUTPUT
          echo "failed_tests=${FAILED_TESTS:-0}" >> $GITHUB_OUTPUT
          echo "total_tests=${TOTAL_TESTS:-0}" >> $GITHUB_OUTPUT
          echo "failure_details=Check golden_test_report.md for details" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$TEST_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: golden-test-results
          path: |
            test_output.json
            golden_test_report.md
            goldens/goldens/
          retention-days: 30

  # Generate Comprehensive Test Report
  test-summary:
    runs-on: ubuntu-latest
    needs: [unit-tests, widget-tests, accessibility-tests, golden-tests]
    outputs:
      overall_status: ${{ steps.report.outputs.overall_status }}
      total_passed: ${{ steps.report.outputs.total_passed }}
      total_failed: ${{ steps.report.outputs.total_failed }}
      total_tests: ${{ steps.report.outputs.total_tests }}
    steps:
      - name: Download test reports
        uses: actions/download-artifact@v4
        with:
          path: test-reports

      - name: Generate comprehensive test report
        id: report
        env:
          UNIT_STATUS: ${{ needs.unit-tests.outputs.status }}
          UNIT_PASSED: ${{ needs.unit-tests.outputs.passed_tests }}
          UNIT_FAILED: ${{ needs.unit-tests.outputs.failed_tests }}
          UNIT_TOTAL: ${{ needs.unit-tests.outputs.total_tests }}
          
          WIDGET_STATUS: ${{ needs.widget-tests.outputs.status }}
          WIDGET_PASSED: ${{ needs.widget-tests.outputs.passed_tests }}
          WIDGET_FAILED: ${{ needs.widget-tests.outputs.failed_tests }}
          WIDGET_TOTAL: ${{ needs.widget-tests.outputs.total_tests }}
          
          ACCESSIBILITY_STATUS: ${{ needs.accessibility-tests.outputs.status }}
          ACCESSIBILITY_PASSED: ${{ needs.accessibility-tests.outputs.passed_tests }}
          ACCESSIBILITY_FAILED: ${{ needs.accessibility-tests.outputs.failed_tests }}
          ACCESSIBILITY_TOTAL: ${{ needs.accessibility-tests.outputs.total_tests }}
          
          GOLDEN_STATUS: ${{ needs.golden-tests.outputs.status }}
          GOLDEN_PASSED: ${{ needs.golden-tests.outputs.passed_tests }}
          GOLDEN_FAILED: ${{ needs.golden-tests.outputs.failed_tests }}
          GOLDEN_TOTAL: ${{ needs.golden-tests.outputs.total_tests }}
        run: |
          echo "Generating comprehensive test report..."
          
          # Calculate totals with proper error handling
          UNIT_PASSED=${UNIT_PASSED:-0}
          WIDGET_PASSED=${WIDGET_PASSED:-0}
          ACCESSIBILITY_PASSED=${ACCESSIBILITY_PASSED:-0}
          GOLDEN_PASSED=${GOLDEN_PASSED:-0}
          
          UNIT_FAILED=${UNIT_FAILED:-0}
          WIDGET_FAILED=${WIDGET_FAILED:-0}
          ACCESSIBILITY_FAILED=${ACCESSIBILITY_FAILED:-0}
          GOLDEN_FAILED=${GOLDEN_FAILED:-0}
          
          TOTAL_PASSED=$((UNIT_PASSED + WIDGET_PASSED + ACCESSIBILITY_PASSED + GOLDEN_PASSED))
          TOTAL_FAILED=$((UNIT_FAILED + WIDGET_FAILED + ACCESSIBILITY_FAILED + GOLDEN_FAILED))
          TOTAL_TESTS=$((TOTAL_PASSED + TOTAL_FAILED))
          
          echo "Debug: UNIT_PASSED=$UNIT_PASSED, WIDGET_PASSED=$WIDGET_PASSED, ACCESSIBILITY_PASSED=$ACCESSIBILITY_PASSED, GOLDEN_PASSED=$GOLDEN_PASSED"
          echo "Debug: TOTAL_PASSED=$TOTAL_PASSED, TOTAL_FAILED=$TOTAL_FAILED, TOTAL_TESTS=$TOTAL_TESTS"
          
          # Determine overall status
          if [ $TOTAL_FAILED -eq 0 ]; then
            OVERALL_STATUS="success"
          else
            OVERALL_STATUS="failure"
          fi
          
          # Create comprehensive report
          cat << EOF > comprehensive_test_report.md
          # 🧪 Comprehensive Test Report
          
          ## 📊 Executive Summary
          
          | Metric | Value |
          |-------|-------|
          | **Overall Status** | $([ "$OVERALL_STATUS" = "success" ] && echo "✅ PASSED" || echo "❌ FAILED") |
          | **Total Tests** | $TOTAL_TESTS |
          | **Passed Tests** | $TOTAL_PASSED |
          | **Failed Tests** | $TOTAL_FAILED |
          | **Success Rate** | $([ $TOTAL_TESTS -gt 0 ] && echo "$((TOTAL_PASSED * 100 / TOTAL_TESTS))%" || echo "0%") |
          
          ## 📋 Detailed Results by Test Suite
          
          ### 🔧 Unit Tests
          - **Status**: $([ "$UNIT_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $UNIT_PASSED/$UNIT_TOTAL passed
          - **Failed Tests**: $UNIT_FAILED
          
          ### 🎨 Widget Tests
          - **Status**: $([ "$WIDGET_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $WIDGET_PASSED/$WIDGET_TOTAL passed
          - **Failed Tests**: $WIDGET_FAILED
          
          ### ♿ Accessibility Tests
          - **Status**: $([ "$ACCESSIBILITY_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $ACCESSIBILITY_PASSED/$ACCESSIBILITY_TOTAL passed
          - **Failed Tests**: $ACCESSIBILITY_FAILED
          
          ### 📸 Golden Tests
          - **Status**: $([ "$GOLDEN_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $GOLDEN_PASSED/$GOLDEN_TOTAL passed
          - **Failed Tests**: $GOLDEN_FAILED
          
          ## 🔍 Failure Analysis
          
          $([ $TOTAL_FAILED -gt 0 ] && echo "### ❌ Failed Test Suites:" || echo "### ✅ All Test Suites Passed!")
          
          $([ "$UNIT_STATUS" = "failed" ] && echo "- **Unit Tests**: Check unit_test_report.md for details" || echo "")
          $([ "$WIDGET_STATUS" = "failed" ] && echo "- **Widget Tests**: Check widget_test_report.md for details" || echo "")
          $([ "$ACCESSIBILITY_STATUS" = "failed" ] && echo "- **Accessibility Tests**: Check accessibility_test_report.md for details" || echo "")
          $([ "$GOLDEN_STATUS" = "failed" ] && echo "- **Golden Tests**: Check golden_test_report.md for details" || echo "")
          
          ## 📁 Test Artifacts
          
          The following test artifacts are available for download:
          - **Unit Test Results**: Available in the workflow artifacts
          - **Widget Test Results**: Available in the workflow artifacts
          - **Accessibility Test Results**: Available in the workflow artifacts
          - **Golden Test Results**: Available in the workflow artifacts (includes golden images)
          
          ## 🚀 Next Steps
          
          $([ "$OVERALL_STATUS" = "success" ] && echo "✅ **All tests passed!** The code is ready for merge." || echo "❌ **Some tests failed.** Please review the failure details above and fix the issues before merging.")
          
          $([ $TOTAL_FAILED -gt 0 ] && echo "
          ### 🔧 Recommended Actions:
          1. Review the failure details for each failed test suite
          2. Run the failing tests locally to reproduce the issues
          3. Fix the identified problems
          4. Re-run the CI pipeline to verify fixes
          5. Only merge when all tests pass" || echo "")
          
          ---
          *Report generated automatically by GitHub Actions CI Pipeline*
          EOF
          
          # Set outputs
          echo "overall_status=$OVERALL_STATUS" >> $GITHUB_OUTPUT
          echo "total_passed=$TOTAL_PASSED" >> $GITHUB_OUTPUT
          echo "total_failed=$TOTAL_FAILED" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          
          # Display the report
          cat comprehensive_test_report.md

      - name: Upload comprehensive report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-report
          path: comprehensive_test_report.md
          retention-days: 30

      - name: Post Test Report as PR Comment
        if: github.event_name == 'pull_request'
        uses: marocchino/sticky-pull-request-comment@v2
        with:
          header: flutter-ci-report
          path: comprehensive_test_report.md

  # Final Status Check - Block PR if any tests fail
  final-status:
    runs-on: ubuntu-latest
    needs: test-summary
    if: github.event_name == 'pull_request'
    steps:
      - name: Check overall test status
        run: |
          if [ "{{ needs.test-summary.outputs.overall_status }}" = "failure" ]; then
            echo "❌ Some tests failed. Pull request cannot be merged."
            echo "Total failed tests: {{ needs.test-summary.outputs.total_failed }}"
            echo "Please review the comprehensive test report and fix all failing tests."
            exit 1
          else
            echo "✅ All tests passed! Pull request is ready for merge."
            echo "Total passed tests: {{ needs.test-summary.outputs.total_passed }}"
          fi 