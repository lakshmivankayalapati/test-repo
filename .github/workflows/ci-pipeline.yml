name: Comprehensive CI Pipeline with Detailed Reporting

on:
  pull_request:
    branches: [ dev, main ]
  push:
    branches: [ dev, main ]

env:
  FLUTTER_VERSION: "3.32.5"
  JAVA_VERSION: "11"
  ANDROID_API_LEVEL: "33"
  ANDROID_BUILD_TOOLS: "33.0.0"

jobs:
  # Unit Tests
  unit-tests:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Run unit tests with detailed reporting
        id: test-results
        run: |
          echo "Running unit tests with comprehensive reporting..."
          
          # Create output directory
          mkdir -p test-results
          
          # Run all unit tests and capture output
          flutter test test/unit/ --reporter=expanded > test-results/unit_test_output.txt 2>&1
          UNIT_EXIT_CODE=$?
          
          # Parse test results using multiple methods
          echo "Parsing unit test results..."
          
          # Method 1: Look for Flutter test summary patterns
          PASSED_COUNT=$(grep -o "✓ [0-9]* tests passed" test-results/unit_test_output.txt 2>/dev/null | grep -o "[0-9]*" | head -1 || echo "0")
          FAILED_COUNT=$(grep -o "✗ [0-9]* tests failed" test-results/unit_test_output.txt 2>/dev/null | grep -o "[0-9]*" | head -1 || echo "0")
          
          # Method 2: Count individual test results if summary not found
          if [ "$PASSED_COUNT" = "0" ] && [ "$FAILED_COUNT" = "0" ]; then
            PASSED_COUNT=$(grep -c "✓" test-results/unit_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
            FAILED_COUNT=$(grep -c "✗" test-results/unit_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
          fi
          
          # Method 3: Look for "All tests passed" or "Some tests failed"
          if [ "$PASSED_COUNT" = "0" ] && [ "$FAILED_COUNT" = "0" ]; then
            if grep -q "All tests passed" test-results/unit_test_output.txt; then
              # Count total test files and assume all passed
              TOTAL_TEST_FILES=$(find test/unit/ -name "*.dart" | wc -l)
              PASSED_COUNT=$TOTAL_TEST_FILES
              FAILED_COUNT=0
            elif grep -q "Some tests failed" test-results/unit_test_output.txt; then
              # Count total test files and assume some failed
              TOTAL_TEST_FILES=$(find test/unit/ -name "*.dart" | wc -l)
              PASSED_COUNT=0
              FAILED_COUNT=$TOTAL_TEST_FILES
            fi
          fi
          
          # Method 4: Manual count based on test file structure
          if [ "$PASSED_COUNT" = "0" ] && [ "$FAILED_COUNT" = "0" ]; then
            echo "Using manual test count method..."
            # Count test files and assume they all ran
            TOTAL_TEST_FILES=$(find test/unit/ -name "*.dart" | wc -l)
            if [ $UNIT_EXIT_CODE -eq 0 ]; then
              PASSED_COUNT=$TOTAL_TEST_FILES
              FAILED_COUNT=0
            else
              PASSED_COUNT=0
              FAILED_COUNT=$TOTAL_TEST_FILES
            fi
          fi
          
          # Ensure we have valid numbers and handle empty results
          if [ -z "$PASSED_COUNT" ] || [ "$PASSED_COUNT" = "" ]; then
            PASSED_TESTS=0
          else
            PASSED_TESTS=$PASSED_COUNT
          fi
          
          if [ -z "$FAILED_COUNT" ] || [ "$FAILED_COUNT" = "" ]; then
            FAILED_TESTS=0
          else
            FAILED_TESTS=$FAILED_COUNT
          fi
          
          # Calculate total with proper arithmetic
          TOTAL_TESTS=$((PASSED_TESTS + FAILED_TESTS))
          
          echo "Debug: PASSED_TESTS=$PASSED_TESTS, FAILED_TESTS=$FAILED_TESTS, TOTAL_TESTS=$TOTAL_TESTS"
          echo "Debug: UNIT_EXIT_CODE=$UNIT_EXIT_CODE"
          echo "Debug: Test output preview:"
          head -20 test-results/unit_test_output.txt
          
          # Extract failure details (first 1000 characters to avoid output size limits)
          FAILURE_DETAILS=""
          if [ "$FAILED_TESTS" -gt 0 ]; then
            FAILURE_DETAILS=$(grep -A 5 -B 2 "✗" test-results/unit_test_output.txt 2>/dev/null | head -20 | tr '\n' ' ' | sed 's/ */ /g' | cut -c1-1000 || echo "No detailed failure info available")
          fi
          
          # Get full test output (truncated to avoid GitHub output limits)
          FULL_OUTPUT=$(cat test-results/unit_test_output.txt | head -1000)
          
          # Determine status
          if [ $UNIT_EXIT_CODE -eq 0 ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "failure_details=$FAILURE_DETAILS" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$FULL_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Exit with the actual test result to properly indicate pass/fail
          exit $UNIT_EXIT_CODE

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: unit-test-results
          path: test-results/
          retention-days: 30

  # Widget Tests
  widget-tests:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Run widget tests with detailed reporting
        id: test-results
        run: |
          echo "Running widget tests with comprehensive reporting..."
          
          # Create output directory
          mkdir -p test-results
          
          # Run widget tests and capture output
          flutter test test/widget_test.dart --reporter=expanded > test-results/widget_test_output.txt 2>&1
          WIDGET_EXIT_CODE=$?
          
          # Parse test results using multiple methods
          echo "Parsing widget test results..."
          
          # Method 1: Look for Flutter test summary patterns
          PASSED_COUNT=$(grep -o "✓ [0-9]* tests passed" test-results/widget_test_output.txt 2>/dev/null | grep -o "[0-9]*" | head -1 || echo "0")
          FAILED_COUNT=$(grep -o "✗ [0-9]* tests failed" test-results/widget_test_output.txt 2>/dev/null | grep -o "[0-9]*" | head -1 || echo "0")
          
          # Method 2: Count individual test results if summary not found
          if [ "$PASSED_COUNT" = "0" ] && [ "$FAILED_COUNT" = "0" ]; then
            PASSED_COUNT=$(grep -c "✓" test-results/widget_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
            FAILED_COUNT=$(grep -c "✗" test-results/widget_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
          fi
          
          # Method 3: Look for "All tests passed" or "Some tests failed"
          if [ "$PASSED_COUNT" = "0" ] && [ "$FAILED_COUNT" = "0" ]; then
            if grep -q "All tests passed" test-results/widget_test_output.txt; then
              PASSED_COUNT=1
              FAILED_COUNT=0
            elif grep -q "Some tests failed" test-results/widget_test_output.txt; then
              PASSED_COUNT=0
              FAILED_COUNT=1
            fi
          fi
          
          # Method 4: Manual count based on test file structure
          if [ "$PASSED_COUNT" = "0" ] && [ "$FAILED_COUNT" = "0" ]; then
            echo "Using manual test count method for widget tests..."
            if [ $WIDGET_EXIT_CODE -eq 0 ]; then
              PASSED_COUNT=1
              FAILED_COUNT=0
            else
              PASSED_COUNT=0
              FAILED_COUNT=1
            fi
          fi
          
          # Ensure we have valid numbers and handle empty results
          if [ -z "$PASSED_COUNT" ] || [ "$PASSED_COUNT" = "" ]; then
            PASSED_TESTS=0
          else
            PASSED_TESTS=$PASSED_COUNT
          fi
          
          if [ -z "$FAILED_COUNT" ] || [ "$FAILED_COUNT" = "" ]; then
            FAILED_TESTS=0
          else
            FAILED_TESTS=$FAILED_COUNT
          fi
          
          # Calculate total with proper arithmetic
          TOTAL_TESTS=$((PASSED_TESTS + FAILED_TESTS))
          
          echo "Debug: PASSED_TESTS=$PASSED_TESTS, FAILED_TESTS=$FAILED_TESTS, TOTAL_TESTS=$TOTAL_TESTS"
          echo "Debug: WIDGET_EXIT_CODE=$WIDGET_EXIT_CODE"
          echo "Debug: Test output preview:"
          head -20 test-results/widget_test_output.txt
          
          # Extract failure details
          FAILURE_DETAILS=""
          if [ "$FAILED_TESTS" -gt 0 ]; then
            FAILURE_DETAILS=$(grep -A 5 -B 2 "✗" test-results/widget_test_output.txt 2>/dev/null | head -20 | tr '\n' ' ' | sed 's/ */ /g' | cut -c1-1000 || echo "No detailed failure info available")
          fi
          
          # Get full test output
          FULL_OUTPUT=$(cat test-results/widget_test_output.txt | head -1000)
          
          # Determine status
          if [ $WIDGET_EXIT_CODE -eq 0 ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "failure_details=$FAILURE_DETAILS" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$FULL_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Exit with the actual test result to properly indicate pass/fail
          exit $WIDGET_EXIT_CODE

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: widget-test-results
          path: test-results/
          retention-days: 30

  # Accessibility Tests
  accessibility-tests:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Run accessibility tests with detailed reporting
        id: test-results
        run: |
          echo "Running accessibility tests with comprehensive reporting..."
          
          # Create output directory
          mkdir -p test-results
          
          # Run accessibility tests and capture output
          flutter test test/accessibility_test.dart --reporter=expanded > test-results/accessibility_test_output.txt 2>&1
          ACCESSIBILITY_EXIT_CODE=$?
          
          # Parse test results
          echo "Parsing accessibility test results..."
          
          # Count passed and failed tests with proper error handling and trim whitespace
          PASSED_COUNT=$(grep -c "✓" test-results/accessibility_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
          FAILED_COUNT=$(grep -c "✗" test-results/accessibility_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
          
          # Ensure we have valid numbers and handle empty results
          if [ -z "$PASSED_COUNT" ] || [ "$PASSED_COUNT" = "" ]; then
            PASSED_TESTS=0
          else
            PASSED_TESTS=$PASSED_COUNT
          fi
          
          if [ -z "$FAILED_COUNT" ] || [ "$FAILED_COUNT" = "" ]; then
            FAILED_TESTS=0
          else
            FAILED_TESTS=$FAILED_COUNT
          fi
          
          # Calculate total with proper arithmetic
          TOTAL_TESTS=$((PASSED_TESTS + FAILED_TESTS))
          
          echo "Debug: PASSED_TESTS=$PASSED_TESTS, FAILED_TESTS=$FAILED_TESTS, TOTAL_TESTS=$TOTAL_TESTS"
          
          # Extract failure details
          FAILURE_DETAILS=""
          if [ "$FAILED_TESTS" -gt 0 ]; then
            FAILURE_DETAILS=$(grep -A 5 -B 2 "✗" test-results/accessibility_test_output.txt 2>/dev/null | head -20 | tr '\n' ' ' | sed 's/ */ /g' | cut -c1-1000 || echo "No detailed failure info available")
          fi
          
          # Get full test output
          FULL_OUTPUT=$(cat test-results/accessibility_test_output.txt | head -1000)
          
          # Determine status
          if [ $ACCESSIBILITY_EXIT_CODE -eq 0 ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "failure_details=$FAILURE_DETAILS" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$FULL_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Exit with the actual test result to properly indicate pass/fail
          exit $ACCESSIBILITY_EXIT_CODE

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: accessibility-test-results
          path: test-results/
          retention-days: 30

  # Golden Tests
  golden-tests:
    runs-on: ubuntu-latest
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Install dependencies for golden tests
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            libgtk-3-dev \
            libwebkit2gtk-4.1-dev \
            libwebkit2gtk-4.0-dev \
            libwebkit2gtk-4.0-37 \
            libwebkit2gtk-4.1-0 \
            xvfb \
            || echo "Some packages not found, continuing with available ones"

      - name: Run golden tests with detailed reporting
        id: test-results
        run: |
          echo "Running golden tests with comprehensive reporting..."
          
          # Create output directory
          mkdir -p test-results
          
          # Run golden tests and capture output
          flutter test goldens/golden_test.dart --reporter=expanded > test-results/golden_test_output.txt 2>&1
          GOLDEN_EXIT_CODE=$?
          
          # Parse test results
          echo "Parsing golden test results..."
          
          # Count passed and failed tests with proper error handling and trim whitespace
          PASSED_COUNT=$(grep -c "✓" test-results/golden_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
          FAILED_COUNT=$(grep -c "✗" test-results/golden_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
          
          # Ensure we have valid numbers and handle empty results
          if [ -z "$PASSED_COUNT" ] || [ "$PASSED_COUNT" = "" ]; then
            PASSED_TESTS=0
          else
            PASSED_TESTS=$PASSED_COUNT
          fi
          
          if [ -z "$FAILED_COUNT" ] || [ "$FAILED_COUNT" = "" ]; then
            FAILED_TESTS=0
          else
            FAILED_TESTS=$FAILED_COUNT
          fi
          
          # Calculate total with proper arithmetic
          TOTAL_TESTS=$((PASSED_TESTS + FAILED_TESTS))
          
          echo "Debug: PASSED_TESTS=$PASSED_TESTS, FAILED_TESTS=$FAILED_TESTS, TOTAL_TESTS=$TOTAL_TESTS"
          
          # Extract failure details
          FAILURE_DETAILS=""
          if [ "$FAILED_TESTS" -gt 0 ]; then
            FAILURE_DETAILS=$(grep -A 5 -B 2 "✗" test-results/golden_test_output.txt 2>/dev/null | head -20 | tr '\n' ' ' | sed 's/ */ /g' | cut -c1-1000 || echo "No detailed failure info available")
          fi
          
          # Get full test output
          FULL_OUTPUT=$(cat test-results/golden_test_output.txt | head -1000)
          
          # Determine status
          if [ $GOLDEN_EXIT_CODE -eq 0 ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "failure_details=$FAILURE_DETAILS" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$FULL_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Exit with the actual test result to properly indicate pass/fail
          exit $GOLDEN_EXIT_CODE

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: golden-test-results
          path: |
            test-results/
            goldens/goldens/
          retention-days: 30

  # Appium Android Tests
  appium-android-tests:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        api-level: [33]  # Android 13
        target: [google_apis]
        arch: [x86_64]
        profile: [AVD]
    outputs:
      status: ${{ steps.test-results.outputs.status }}
      passed_tests: ${{ steps.test-results.outputs.passed_tests }}
      failed_tests: ${{ steps.test-results.outputs.failed_tests }}
      total_tests: ${{ steps.test-results.outputs.total_tests }}
      failure_details: ${{ steps.test-results.outputs.failure_details }}
      test_output: ${{ steps.test-results.outputs.test_output }}
    steps:
      - name: Checkout code
        uses: actions/checkout@v4

      - name: Setup Java
        uses: actions/setup-java@v4
        with:
          distribution: 'temurin'
          java-version: '11'

      - name: Setup Flutter
        uses: subosito/flutter-action@v2
        with:
          flutter-version: ${{ env.FLUTTER_VERSION }}
          channel: 'stable'

      - name: Get dependencies
        run: flutter pub get

      - name: Setup Android Emulator
        uses: reactivecircus/android-emulator-runner@v2
        with:
          api-level: ${{ matrix.api-level }}
          target: ${{ matrix.target }}
          arch: ${{ matrix.arch }}
          profile: ${{ matrix.profile }}
          avd-name: test-device
          emulator-options: -no-window -gpu swiftshader_indirect -noaudio -no-boot-anim -camera-back none -camera-front none -wipe-data
          script: |
            echo "Android emulator is running"
            adb devices
            adb shell getprop ro.build.version.release

      - name: Install Appium dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y \
            nodejs \
            npm \
            || echo "Some packages not found, continuing with available ones"

      - name: Install Appium
        run: |
          npm install -g appium
          appium driver install uiautomator2

      - name: Build APK
        run: |
          flutter build apk --release

      - name: Install APK on emulator
        run: |
          adb install build/app/outputs/flutter-apk/app-release.apk

      - name: Start Appium server
        run: |
          appium --base-path /wd/hub &
          sleep 10

      - name: Run Appium Android tests with detailed reporting
        id: test-results
        run: |
          echo "Running Appium Android tests with comprehensive reporting..."
          
          # Create output directory
          mkdir -p test-results
          
          # Run Appium Android tests and capture output
          # Note: The test will run in the emulator environment
          dart run appium_tests/android13_test.dart > test-results/appium_android_test_output.txt 2>&1
          APPIUM_ANDROID_EXIT_CODE=$?
          
          # Parse test results using multiple methods
          echo "Parsing Appium Android test results..."
          
          # Method 1: Look for success/failure patterns
          PASSED_COUNT=$(grep -c "✅" test-results/appium_android_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
          FAILED_COUNT=$(grep -c "❌" test-results/appium_android_test_output.txt 2>/dev/null | tr -d '\n\r' || echo "0")
          
          # Method 2: Look for specific success messages
          if [ "$PASSED_COUNT" = "0" ] && [ "$FAILED_COUNT" = "0" ]; then
            if grep -q "All Android 13 Pixel 4a tests completed successfully" test-results/appium_android_test_output.txt; then
              PASSED_COUNT=1
              FAILED_COUNT=0
            elif grep -q "Test failed" test-results/appium_android_test_output.txt; then
              PASSED_COUNT=0
              FAILED_COUNT=1
            fi
          fi
          
          # Method 3: Manual count based on exit code
          if [ "$PASSED_COUNT" = "0" ] && [ "$FAILED_COUNT" = "0" ]; then
            echo "Using manual test count method for Appium Android tests..."
            if [ $APPIUM_ANDROID_EXIT_CODE -eq 0 ]; then
              PASSED_COUNT=1
              FAILED_COUNT=0
            else
              PASSED_COUNT=0
              FAILED_COUNT=1
            fi
          fi
          
          # Ensure we have valid numbers and handle empty results
          if [ -z "$PASSED_COUNT" ] || [ "$PASSED_COUNT" = "" ]; then
            PASSED_TESTS=0
          else
            PASSED_TESTS=$PASSED_COUNT
          fi
          
          if [ -z "$FAILED_COUNT" ] || [ "$FAILED_COUNT" = "" ]; then
            FAILED_TESTS=0
          else
            FAILED_TESTS=$FAILED_COUNT
          fi
          
          # Calculate total with proper arithmetic
          TOTAL_TESTS=$((PASSED_TESTS + FAILED_TESTS))
          
          echo "Debug: PASSED_TESTS=$PASSED_TESTS, FAILED_TESTS=$FAILED_TESTS, TOTAL_TESTS=$TOTAL_TESTS"
          echo "Debug: APPIUM_ANDROID_EXIT_CODE=$APPIUM_ANDROID_EXIT_CODE"
          echo "Debug: Test output preview:"
          head -20 test-results/appium_android_test_output.txt
          
          # Extract failure details
          FAILURE_DETAILS=""
          if [ "$FAILED_TESTS" -gt 0 ]; then
            FAILURE_DETAILS=$(grep -A 5 -B 2 "❌" test-results/appium_android_test_output.txt 2>/dev/null | head -20 | tr '\n' ' ' | sed 's/ */ /g' | cut -c1-1000 || echo "No detailed failure info available")
          fi
          
          # Get full test output
          FULL_OUTPUT=$(cat test-results/appium_android_test_output.txt | head -1000)
          
          # Determine status
          if [ $APPIUM_ANDROID_EXIT_CODE -eq 0 ]; then
            STATUS="passed"
          else
            STATUS="failed"
          fi
          
          # Set outputs
          echo "status=$STATUS" >> $GITHUB_OUTPUT
          echo "passed_tests=$PASSED_TESTS" >> $GITHUB_OUTPUT
          echo "failed_tests=$FAILED_TESTS" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          echo "failure_details=$FAILURE_DETAILS" >> $GITHUB_OUTPUT
          echo "test_output<<EOF" >> $GITHUB_OUTPUT
          echo "$FULL_OUTPUT" >> $GITHUB_OUTPUT
          echo "EOF" >> $GITHUB_OUTPUT
          
          # Exit with the actual test result to properly indicate pass/fail
          exit $APPIUM_ANDROID_EXIT_CODE

      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: appium-android-test-results
          path: |
            test-results/
            build/app/outputs/flutter-apk/
          retention-days: 30

  # Generate Comprehensive Test Report
  test-summary:
    runs-on: ubuntu-latest
    needs: [unit-tests, widget-tests, accessibility-tests, golden-tests, appium-android-tests]
    outputs:
      overall_status: ${{ steps.report.outputs.overall_status }}
      total_passed: ${{ steps.report.outputs.total_passed }}
      total_failed: ${{ steps.report.outputs.total_failed }}
      total_tests: ${{ steps.report.outputs.total_tests }}
    steps:
      - name: Generate comprehensive test report
        id: report
        env:
          UNIT_STATUS: ${{ needs.unit-tests.outputs.status }}
          UNIT_PASSED: ${{ needs.unit-tests.outputs.passed_tests }}
          UNIT_FAILED: ${{ needs.unit-tests.outputs.failed_tests }}
          UNIT_TOTAL: ${{ needs.unit-tests.outputs.total_tests }}
          UNIT_FAILURE_DETAILS: ${{ needs.unit-tests.outputs.failure_details }}
          
          WIDGET_STATUS: ${{ needs.widget-tests.outputs.status }}
          WIDGET_PASSED: ${{ needs.widget-tests.outputs.passed_tests }}
          WIDGET_FAILED: ${{ needs.widget-tests.outputs.failed_tests }}
          WIDGET_TOTAL: ${{ needs.widget-tests.outputs.total_tests }}
          WIDGET_FAILURE_DETAILS: ${{ needs.widget-tests.outputs.failure_details }}
          
          ACCESSIBILITY_STATUS: ${{ needs.accessibility-tests.outputs.status }}
          ACCESSIBILITY_PASSED: ${{ needs.accessibility-tests.outputs.passed_tests }}
          ACCESSIBILITY_FAILED: ${{ needs.accessibility-tests.outputs.failed_tests }}
          ACCESSIBILITY_TOTAL: ${{ needs.accessibility-tests.outputs.total_tests }}
          ACCESSIBILITY_FAILURE_DETAILS: ${{ needs.accessibility-tests.outputs.failure_details }}
          
          GOLDEN_STATUS: ${{ needs.golden-tests.outputs.status }}
          GOLDEN_PASSED: ${{ needs.golden-tests.outputs.passed_tests }}
          GOLDEN_FAILED: ${{ needs.golden-tests.outputs.failed_tests }}
          GOLDEN_TOTAL: ${{ needs.golden-tests.outputs.total_tests }}
          GOLDEN_FAILURE_DETAILS: ${{ needs.golden-tests.outputs.failure_details }}
          
          APPIUM_ANDROID_STATUS: ${{ needs.appium-android-tests.outputs.status }}
          APPIUM_ANDROID_PASSED: ${{ needs.appium-android-tests.outputs.passed_tests }}
          APPIUM_ANDROID_FAILED: ${{ needs.appium-android-tests.outputs.failed_tests }}
          APPIUM_ANDROID_TOTAL: ${{ needs.appium-android-tests.outputs.total_tests }}
          APPIUM_ANDROID_FAILURE_DETAILS: ${{ needs.appium-android-tests.outputs.failure_details }}
        run: |
          echo "Generating comprehensive test report..."
          
          # Debug: Print all environment variables
          echo "=== Environment Variables Debug ==="
          echo "UNIT_STATUS: '$UNIT_STATUS'"
          echo "UNIT_PASSED: '$UNIT_PASSED'"
          echo "UNIT_FAILED: '$UNIT_FAILED'"
          echo "UNIT_TOTAL: '$UNIT_TOTAL'"
          echo "WIDGET_STATUS: '$WIDGET_STATUS'"
          echo "WIDGET_PASSED: '$WIDGET_PASSED'"
          echo "WIDGET_FAILED: '$WIDGET_FAILED'"
          echo "WIDGET_TOTAL: '$WIDGET_TOTAL'"
          echo "ACCESSIBILITY_STATUS: '$ACCESSIBILITY_STATUS'"
          echo "ACCESSIBILITY_PASSED: '$ACCESSIBILITY_PASSED'"
          echo "ACCESSIBILITY_FAILED: '$ACCESSIBILITY_FAILED'"
          echo "ACCESSIBILITY_TOTAL: '$ACCESSIBILITY_TOTAL'"
          echo "GOLDEN_STATUS: '$GOLDEN_STATUS'"
          echo "GOLDEN_PASSED: '$GOLDEN_PASSED'"
          echo "GOLDEN_FAILED: '$GOLDEN_FAILED'"
          echo "GOLDEN_TOTAL: '$GOLDEN_TOTAL'"
          echo "=================================="
          
          # Calculate totals with proper error handling
          UNIT_PASSED=${UNIT_PASSED:-0}
          WIDGET_PASSED=${WIDGET_PASSED:-0}
          ACCESSIBILITY_PASSED=${ACCESSIBILITY_PASSED:-0}
          GOLDEN_PASSED=${GOLDEN_PASSED:-0}
          APPIUM_ANDROID_PASSED=${APPIUM_ANDROID_PASSED:-0}
          
          UNIT_FAILED=${UNIT_FAILED:-0}
          WIDGET_FAILED=${WIDGET_FAILED:-0}
          ACCESSIBILITY_FAILED=${ACCESSIBILITY_FAILED:-0}
          GOLDEN_FAILED=${GOLDEN_FAILED:-0}
          APPIUM_ANDROID_FAILED=${APPIUM_ANDROID_FAILED:-0}
          
          TOTAL_PASSED=$((UNIT_PASSED + WIDGET_PASSED + ACCESSIBILITY_PASSED + GOLDEN_PASSED + APPIUM_ANDROID_PASSED))
          TOTAL_FAILED=$((UNIT_FAILED + WIDGET_FAILED + ACCESSIBILITY_FAILED + GOLDEN_FAILED + APPIUM_ANDROID_FAILED))
          TOTAL_TESTS=$((TOTAL_PASSED + TOTAL_FAILED))
          
          echo "Debug: UNIT_PASSED=$UNIT_PASSED, WIDGET_PASSED=$WIDGET_PASSED, ACCESSIBILITY_PASSED=$ACCESSIBILITY_PASSED, GOLDEN_PASSED=$GOLDEN_PASSED, APPIUM_ANDROID_PASSED=$APPIUM_ANDROID_PASSED"
          echo "Debug: TOTAL_PASSED=$TOTAL_PASSED, TOTAL_FAILED=$TOTAL_FAILED, TOTAL_TESTS=$TOTAL_TESTS"
          
          # Determine overall status
          if [ $TOTAL_FAILED -eq 0 ]; then
            OVERALL_STATUS="success"
          else
            OVERALL_STATUS="failure"
          fi
          
          # Create comprehensive report
          cat << EOF > comprehensive_test_report.md
          # 🧪 Comprehensive Test Report
          
          ## 📊 Executive Summary
          
          | Metric | Value |
          |-------|-------|
          | **Overall Status** | $([ "$OVERALL_STATUS" = "success" ] && echo "✅ PASSED" || echo "❌ FAILED") |
          | **Total Tests** | $TOTAL_TESTS |
          | **Passed Tests** | $TOTAL_PASSED |
          | **Failed Tests** | $TOTAL_FAILED |
          | **Success Rate** | $([ $TOTAL_TESTS -gt 0 ] && echo "$((TOTAL_PASSED * 100 / TOTAL_TESTS))%" || echo "0%") |
          
          ## 📋 Detailed Results by Test Suite
          
          ### 🔧 Unit Tests
          - **Status**: $([ "$UNIT_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $UNIT_PASSED/$UNIT_TOTAL passed
          - **Failed Tests**: $UNIT_FAILED
          $([ "$UNIT_STATUS" = "failed" ] && echo "- **Failure Details**: $UNIT_FAILURE_DETAILS" || echo "")
          
          ### 🎨 Widget Tests
          - **Status**: $([ "$WIDGET_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $WIDGET_PASSED/$WIDGET_TOTAL passed
          - **Failed Tests**: $WIDGET_FAILED
          $([ "$WIDGET_STATUS" = "failed" ] && echo "- **Failure Details**: $WIDGET_FAILURE_DETAILS" || echo "")
          
          ### ♿ Accessibility Tests
          - **Status**: $([ "$ACCESSIBILITY_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $ACCESSIBILITY_PASSED/$ACCESSIBILITY_TOTAL passed
          - **Failed Tests**: $ACCESSIBILITY_FAILED
          $([ "$ACCESSIBILITY_STATUS" = "failed" ] && echo "- **Failure Details**: $ACCESSIBILITY_FAILURE_DETAILS" || echo "")
          
          ### 📸 Golden Tests
          - **Status**: $([ "$GOLDEN_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $GOLDEN_PASSED/$GOLDEN_TOTAL passed
          - **Failed Tests**: $GOLDEN_FAILED
          $([ "$GOLDEN_STATUS" = "failed" ] && echo "- **Failure Details**: $GOLDEN_FAILURE_DETAILS" || echo "")
          
          ### 🤖 Appium Android Tests
          - **Status**: $([ "$APPIUM_ANDROID_STATUS" = "passed" ] && echo "✅ PASSED" || echo "❌ FAILED")
          - **Tests**: $APPIUM_ANDROID_PASSED/$APPIUM_ANDROID_TOTAL passed
          - **Failed Tests**: $APPIUM_ANDROID_FAILED
          $([ "$APPIUM_ANDROID_STATUS" = "failed" ] && echo "- **Failure Details**: $APPIUM_ANDROID_FAILURE_DETAILS" || echo "")
          
          ## 🔍 Failure Analysis
          
          $([ $TOTAL_FAILED -gt 0 ] && echo "### ❌ Failed Test Suites:" || echo "### ✅ All Test Suites Passed!")
          
          $([ "$UNIT_STATUS" = "failed" ] && echo "- **Unit Tests**: $UNIT_FAILURE_DETAILS" || echo "")
          $([ "$WIDGET_STATUS" = "failed" ] && echo "- **Widget Tests**: $WIDGET_FAILURE_DETAILS" || echo "")
          $([ "$ACCESSIBILITY_STATUS" = "failed" ] && echo "- **Accessibility Tests**: $ACCESSIBILITY_FAILURE_DETAILS" || echo "")
          $([ "$GOLDEN_STATUS" = "failed" ] && echo "- **Golden Tests**: $GOLDEN_FAILURE_DETAILS" || echo "")
          $([ "$APPIUM_ANDROID_STATUS" = "failed" ] && echo "- **Appium Android Tests**: $APPIUM_ANDROID_FAILURE_DETAILS" || echo "")
          
          ## 📁 Test Artifacts
          
          The following test artifacts are available for download:
          - **Unit Test Results**: Available in the workflow artifacts
          - **Widget Test Results**: Available in the workflow artifacts
          - **Accessibility Test Results**: Available in the workflow artifacts
          - **Golden Test Results**: Available in the workflow artifacts (includes golden images)
          - **Appium Android Test Results**: Available in the workflow artifacts (includes APK and test logs)
          
          ## 🚀 Next Steps
          
          $([ "$OVERALL_STATUS" = "success" ] && echo "✅ **All tests passed!** The code is ready for merge." || echo "❌ **Some tests failed.** Please review the failure details above and fix the issues before merging.")
          
          $([ $TOTAL_FAILED -gt 0 ] && echo "
          ### 🔧 Recommended Actions:
          1. Review the failure details for each failed test suite
          2. Run the failing tests locally to reproduce the issues
          3. Fix the identified problems
          4. Re-run the CI pipeline to verify fixes
          5. Only merge when all tests pass" || echo "")
          
          ---
          *Report generated automatically by GitHub Actions CI Pipeline*
          EOF
          
          # Set outputs
          echo "overall_status=$OVERALL_STATUS" >> $GITHUB_OUTPUT
          echo "total_passed=$TOTAL_PASSED" >> $GITHUB_OUTPUT
          echo "total_failed=$TOTAL_FAILED" >> $GITHUB_OUTPUT
          echo "total_tests=$TOTAL_TESTS" >> $GITHUB_OUTPUT
          
          # Display the report
          cat comprehensive_test_report.md

      - name: Upload comprehensive report
        uses: actions/upload-artifact@v4
        with:
          name: comprehensive-test-report
          path: comprehensive_test_report.md
          retention-days: 30

      - name: Comment on PR with test results
        if: github.event_name == 'pull_request'
        uses: actions/github-script@v7
        with:
          script: |
            const fs = require('fs');
            const report = fs.readFileSync('comprehensive_test_report.md', 'utf8');
            
            github.rest.issues.createComment({
              issue_number: context.issue.number,
              owner: context.repo.owner,
              repo: context.repo.repo,
              body: report
            });

  # Final Status Check - Block PR if any tests fail
  final-status:
    runs-on: ubuntu-latest
    needs: test-summary
    if: github.event_name == 'pull_request'
    steps:
      - name: Check overall test status
        run: |
          if [ "{{ needs.test-summary.outputs.overall_status }}" = "failure" ]; then
            echo "❌ Some tests failed. Pull request cannot be merged."
            echo "Total failed tests: {{ needs.test-summary.outputs.total_failed }}"
            echo "Please review the comprehensive test report and fix all failing tests."
            exit 1
          else
            echo "✅ All tests passed! Pull request is ready for merge."
            echo "Total passed tests: {{ needs.test-summary.outputs.total_passed }}"
          fi 